{"cells":[{"cell_type":"markdown","metadata":{"id":"nMuaQpJ7hfjK"},"source":["# Different Model Prompts"]},{"cell_type":"markdown","metadata":{"id":"-YVkDLiWl2mu"},"source":["# LLMs(Current)"]},{"cell_type":"markdown","metadata":{"id":"fY9UGuPIhOSS"},"source":["## GPT family and Claude family and Mistral Model\n","\n","**Prompts with Langchain:The langchain use in different models are similar, the difference are initaliztion of chat model and combine them to invoke model to generate output.**\n","\n","\n"]},{"cell_type":"markdown","source":["### Initlization and Invoke"],"metadata":{"id":"5MK8O2rqClvo"}},{"cell_type":"markdown","source":["***Initlialize the chat model***"],"metadata":{"id":"tWYEZRFoP2vD"}},{"cell_type":"code","source":["# Initialize the chat model\n","\n","\"\"\"\n","GPT Faimily\n","model_name=\"gpt-4o-mini\"/\"gpt-4-turbo\"/\"gpt-3.5-turbo\"\n","\n","\"\"\"\n","\n","llm = OpenAIChat(model_name='The Model Name With Its Version',temperature=0,max_tokens=50)\n","\n","\n","\"\"\"\"\n","Claude Family\n","\"\"\"\n","\n","boto3_bedrock = boto3.client('bedrock-runtime')\n","\n","# Define the model ID and parameters\n","model_id = \"us.anthropic.claude-3-5-haiku-20241022-v1:0\"\n","#model_id = \"us.anthropic.claude-3-5-sonnet-20240620-v1:0\"\n","model_kwargs = {\n","    \"max_tokens\": 50,  # Claude-3 use “max_tokens” However Claude-2 requires “max_tokens_to_sample”.\n","    \"temperature\": 0.2,\n","    \"top_k\": 250,\n","    \"top_p\": 0.999,\n","    #\"stop_sequences\": [\"\\n\\nHuman\"],\n","    \"stop_sequences\":[],\n","}\n","\n","# Initialize the BedrockChat instance\n","claude3 = ChatBedrock(\n","    client=boto3_bedrock,\n","    model_id=model_id,\n","    model_kwargs=model_kwargs,\n",")\n","\n","\"\"\"\n","Mistral Model\n","\"\"\"\n","\n","boto3_bedrock = boto3.client('bedrock-runtime', 'us-east-1')\n","\n","# Define the model ID and parameters\n","model_id = \"mistral.mistral-7b-instruct-v0:2\"\n","model_kwargs = {\n","    \"max_tokens\": 50,  # Adjust as needed based on the model's requirements\n","    \"temperature\": 0.2\n","}\n","\n","# Initialize the BedrockChat instance\n","mistral = BedrockChat(\n","    client=boto3_bedrock,\n","    model_id=model_id,\n","    model_kwargs=model_kwargs,\n",")\n"],"metadata":{"id":"hjV2Q-avOS6A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["***Embed the prompt to invoke model and parse output***"],"metadata":{"id":"Ow5UF0SFQFuG"}},{"cell_type":"code","source":["\"\"\"GPT Family\"\"\"\n","\n","prompt_value = prompt.format(user_input=\"The Pinyin Input\")\n","llm_output = llm(prompt_value)\n","\n","# Parse the output\n","response = output_parser.parse(llm_output)\n","print(response.get(\"ime_string\"))\n","\n","\"\"\"Claude Family\"\"\"\n","# Combine the prompt, model, and output parser into a chain\n","chain = prompt | claude3 | output_parser\n","response = chain.invoke({\"user_input\": \"The Pinyin Input\"})\n","print(response.get(\"ime_string\"))\n","\n","\"\"\" Mistral Model\"\"\"\n","\n","chain = prompt | mistral | output_parser\n","response = chain.invoke({\"user_input\": \"The Pinyin Input\"})"],"metadata":{"id":"SlmqsLFbQOnS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","###### Examples of combining prompt and instructions\n","\n","Following the complete example using gpt4o-mini and claude3.5 Haiku, same with other gpt claude models"],"metadata":{"id":"izTM2shESeSH"}},{"cell_type":"code","source":["'''GPT example'''\n","\n","# Initialize the chat model\n","llm = OpenAIChat(model_name=\"gpt-4o-mini\",temperature=0,max_tokens=50)\n","\n","\n","# Define the response schemas\n","response_schemas = [\n","    ResponseSchema(name=\"original_string\", description=\"This an user input Pinyin string\"),\n","    ResponseSchema(name=\"ime_string\", description=\"This is your first response, the Chinese response\")\n","]\n","# Initialize the output parser\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","\n","# Get the format instructions\n","format_instructions = output_parser.get_format_instructions()\n","\n","\n","# Define the ***Prompt Template***\n","template = \"\"\"\n","You will be given a Pinyin with tone from a user, try to output the corresponding Chinese.\n","\n","{format_instructions}\n","\n","% USER INPUT:\n","{user_input}\n","\n","YOUR RESPONSE:\n","\"\"\"\n","\n","# Leverage the prompt template\n","prompt = PromptTemplate(\n","    input_variables=[\"user_input\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n","    template=template\n",")\n","\n","prompt_value = prompt.format(user_input=\"jin tian shi ge hao ri zi\")\n","llm_output = llm(prompt_value)"],"metadata":{"id":"--Y3cecLZYjE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I5T9Dtk-SAXg"},"outputs":[],"source":["\"\"\"Claude3.5 Haiku Example\"\"\"\n","boto3_bedrock = boto3.client('bedrock-runtime')\n","\n","# Define the model ID and parameters\n","model_id = \"us.anthropic.claude-3-5-haiku-20241022-v1:0\"\n","model_kwargs = {\n","    \"max_tokens\": 50,  # Claude-3 use “max_tokens” However Claude-2 requires “max_tokens_to_sample”.\n","    \"temperature\": 0.2,\n","    \"top_k\": 250,\n","    \"top_p\": 0.999,\n","    \"stop_sequences\":[],\n","}\n","\n","# Initialize the BedrockChat instance\n","claude3 = ChatBedrock(\n","    client=boto3_bedrock,\n","    model_id=model_id,\n","    model_kwargs=model_kwargs,\n",")\n","\n","# Define the response schemas\n","response_schemas = [\n","    ResponseSchema(name=\"original_string\", description=\"This is a user input Pinyin string\"),\n","    ResponseSchema(name=\"ime_string\", description=\"This is your first response, the Chinese response\")\n","]\n","\n","# Initialize the output parser\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","\n","# Get the format instructions\n","format_instructions = output_parser.get_format_instructions()\n","\n","# Define the prompt template\n","template = \"\"\"\n","You will be given a Pinyin with tone from a user, try to output the corresponding Chinese.\n","\n","{format_instructions}\n","\n","% USER INPUT:\n","{user_input}\n","\n","YOUR RESPONSE:\n","\"\"\"\n","\n","# Initialize the prompt template\n","prompt = PromptTemplate(\n","    input_variables=[\"user_input\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n","    template=template\n",")\n","\n","# Combine the prompt, model, and output parser into a chain\n","chain = prompt | claude3 | output_parser\n","\n","\n","# Chain Invoke\n","response = chain.invoke({\"user_input\": \"jin tian shi ge hao ri zi\"})\n","print(response.get(\"ime_string\"))"]},{"cell_type":"code","source":["\"\"\"Mistral Example\"\"\"\n","# Create a Bedrock Runtime client in the AWS Region you want to use.\n","bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n","\n","# Set the model ID, e.g., Mistral.\n","model_id = \"mistral.mistral-7b-instruct-v0:2\"\n","model_kwargs = {\n","    \"max_tokens\": 50,\n","    \"temperature\": 0.2,\n","}\n","\n","# LangChain class for chat\n","model = ChatBedrock(\n","    client=bedrock_runtime,\n","    model_id=model_id,\n","    model_kwargs=model_kwargs,\n",")\n","\n","# Define the response schemas\n","response_schemas = [\n","    ResponseSchema(name=\"original_string\", description=\"This an user input Pinyin sentence\"),\n","    ResponseSchema(name=\"corrected_string\", description=\"This is your first response, the Chinese response\")\n","    ]\n","# Initialize the output parser\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","\n","# Get the format instructions\n","format_instructions = output_parser.get_format_instructions()\n","\n","# Define the prompt template\n","messages = [\n","    (\"system\", \"\"\"\n","    You will be given pinyin strings from a user. Try to output the corresponding Chinese.\n","    \"\"\"),\n","    (\"human\", \"\"\"\n","    {format_instructions}\n","\n","    % USER INPUT:\n","    {user_input}\n","\n","    YOUR RESPONSE:\n","    \"\"\")\n","]\n","\n","# Configure Prompt and Chain (using LCEL)\n","prompt = ChatPromptTemplate.from_messages(messages)\n","chain = prompt | mistral | output_parser\n","\n","# Invoke the chain\n","\n","response = chain.invoke({\"user_input\": \"jie guo, qi zhong de 33 feng xin mei le xia ruo.\", \"format_instructions\": format_instructions})\n","\n","# Print the corresponding Chinese characters from \"corrected_string\"\n","corrected_string = response.get(\"corrected_string\", \"No corrected_string found\")\n","print(corrected_string)\n"],"metadata":{"id":"ZW_jdV-2VnoC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Text Generation"],"metadata":{"id":"T-YWafZTEzfP"}},{"cell_type":"markdown","metadata":{"id":"LUSj-7XesSF6"},"source":["##### Prompt  for Chinese Words\n","\n","df=\"Chinese_Words\"\n"]},{"cell_type":"code","source":["## Define the response schemas\n","response_schemas = [\n","    ResponseSchema(name=\"original_string\", description=\"This is a user input Pinyin string\"),\n","    ResponseSchema(name=\"ime_string\", description=\"This is your first response, the Chinese response\")\n","]\n","# Initialize the output parser\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","# Get the format instructions\n","format_instructions = output_parser.get_format_instructions()"],"metadata":{"id":"Tbsr1jp2Sd_R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","### Define thePrompt Template for GPT and Claude\n","\n","\n","template = \"\"\"\n","You will be given a Pinyin with tone from a user, try to output the corresponding Chinese.\n","\n","{format_instructions}\n","\n","% USER INPUT:\n","{user_input}\n","\n","YOUR RESPONSE:\n","\"\"\"\n","\n","\n","## Leverage the prompt template\n","prompt = PromptTemplate(\n","    input_variables=[\"user_input\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n","    template=template\n",")"],"metadata":{"id":"DAc6nhcZZBdO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","### Define the ***Prompt Template for Mistral\n","\n","\n","messages = [\n","    (\"system\", \"\"\"\n","    You will be given pinyin strings from a user. Try to output the corresponding Chinese.\n","    \"\"\"),\n","    (\"human\", \"\"\"\n","    {format_instructions}\n","\n","    % USER INPUT:\n","    {user_input}\n","\n","    YOUR RESPONSE:\n","    \"\"\")\n","]\n","\n","# Configure Prompt and Chain (using LCEL)\n","prompt = ChatPromptTemplate.from_messages(messages)"],"metadata":{"id":"NqT_pxQgXnjN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V_rPc7Qa8FGq"},"source":["##### Prompts for Chinese Sentences"]},{"cell_type":"markdown","source":["**Simplified Chinese**"],"metadata":{"id":"6_h39yz0DUF2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3RNmDqi78Mt2"},"outputs":[],"source":["response_schemas = [\n","    ResponseSchema(name=\"original_string\", description=\"This a formatted user input pinyin string\"),\n","    ResponseSchema(name=\"ime_string\", description=\"This is your first response, the Simplified Chinese sentences response\")\n","]\n","\n","#Initialization\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","\n","format_instructions = output_parser.get_format_instructions()\n","\n","\n","\"\"\"GPT and Claude\"\"\"\n","\n","template = \"\"\"\n","You will be given a formatted pinyin strings from a user.\n","Printout its Simplified Chinese sentences by the given string.\n","\n","{format_instructions}\n","\n","% USER INPUT:\n","{user_input}\n","\n","YOUR RESPONSE:\n","\"\"\"\n"]},{"cell_type":"code","source":["\"\"\"Mistral\"\"\"\n","### Define the ***Prompt Template for Mistral\n","\n","messages = [\n","    (\"system\", \"\"\"\n","    You will be given pinyin strings from a user. Try to its Simplified Chinese sentences.\n","    \"\"\"),\n","    (\"human\", \"\"\"\n","    {format_instructions}\n","\n","    % USER INPUT:\n","    {user_input}\n","\n","    YOUR RESPONSE:\n","    \"\"\")\n","]\n","\n","# Configure Prompt and Chain (using LCEL)\n","prompt = ChatPromptTemplate.from_messages(messages)\n","# Invoke the chain\n","\n","response = chain.invoke({\"user_input\": \"The Pinyin Input\", \"format_instructions\": format_instructions})\n","\n","# Print the corresponding Chinese characters from \"corrected_string\"\n","print(response.get(\"ime_string\", \"No ime_string found\"))"],"metadata":{"id":"rSXflb1fYbcU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Traditional Chinese**"],"metadata":{"id":"2oSnZ4ilDZCR"}},{"cell_type":"code","source":["response_schemas = [\n","    ResponseSchema(name=\"original_string\", description=\"This a formatted user input pinyin string\"),\n","    ResponseSchema(name=\"ime_string\", description=\"This is your first response, the Traditional Chinese sentences response\")\n","]\n","\n","#Initialization\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","\n","format_instructions = output_parser.get_format_instructions()\n","\n","template = \"\"\"\n","You will be given a formatted pinyin strings from a user.\n","Printout its Traditional Chinese sentences by the given string.\n","\n","{format_instructions}\n","\n","% USER INPUT:\n","{user_input}\n","\n","YOUR RESPONSE:\n","\"\"\"\n","\n","\n","\n","\n","\n","# Embed our format description into prompt and tell llm what format we want him to output\n","prompt = PromptTemplate(\n","    input_variables=[\"user_input\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n","    template=template\n",")\n","prompt_value = prompt.format(user_input=\"The Pinyin Input\")\n","llm_output = llm(prompt_value)\n","# Parse the output\n","parsed_output = output_parser.parse(llm_output).get(\"ime_string\")\n","print(parsed_output)"],"metadata":{"id":"gI_nImonDX0l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"Mistral\"\"\"\n","### Define the ***Prompt Template for Mistral\n","\n","messages = [\n","    (\"system\", \"\"\"\n","    You will be given pinyin strings from a user. Try to its Traditional Chinese sentences.\n","    \"\"\"),\n","    (\"human\", \"\"\"\n","    {format_instructions}\n","\n","    % USER INPUT:\n","    {user_input}\n","\n","    YOUR RESPONSE:\n","    \"\"\")\n","]\n","\n","# Configure Prompt and Chain (using LCEL)\n","prompt = ChatPromptTemplate.from_messages(messages)\n","chain = prompt | mistral | output_parser\n","\n","\n","\n","# Invoke the chain\n","\n","response = chain.invoke({\"user_input\": \"The Pinyin Input\", \"format_instructions\": format_instructions})\n","\n","# Print the corresponding Chinese characters from \"ime_string\"\n","response.get(\"ime_string\", \"No ime_string found\")\n"],"metadata":{"id":"_v5S0N9AyPNW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D5D8yweat-Dk"},"source":["##### Prompt for Japanese Words\n","\n","\n","df=\"Japanese_Words\""]},{"cell_type":"code","source":["response_schemas = [\n","    ResponseSchema(name=\"original_string\", description=\"This a formatted user input romanji string\"),\n","    ResponseSchema(name=\"ime_string\", description=\"This is your first response, the Japanese response\")\n","]\n","\n","#Initialization\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","\n","format_instructions = output_parser.get_format_instructions()"],"metadata":{"id":"9-XzahVuDuUl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Kanji**"],"metadata":{"id":"ZkMKkC-sDmrp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iwMocG7duDor"},"outputs":[],"source":["template_kanji = \"\"\"\n","You will be given a formatted romanji string from a user.\n","Printout its Kanji by the given string.\n","\n","{format_instructions}\n","\n","% USER INPUT:\n","{user_input}\n","\n","YOUR RESPONSE:\n","\"\"\"\n","\n","# Embed our format description into prompt and tell llm what format we want him to output\n","prompt_kanji= PromptTemplate(\n","    input_variables=[\"user_input\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n","    template=template_kanji\n",")"]},{"cell_type":"markdown","source":["**Hiragana**"],"metadata":{"id":"r9r0lkTnD3AM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LcaN9YM8Ow3r"},"outputs":[],"source":["template_hira = \"\"\"\n","You will be given a formatted romanji string from a user.\n","Printout its Hiragana by the given string.\n","\n","{format_instructions}\n","\n","% USER INPUT:\n","{user_input}\n","\n","YOUR RESPONSE:\n","\"\"\"\n","\n","# Embed our format description into prompt and tell llm what format we want him to output\n","prompt_hira = PromptTemplate(\n","    input_variables=[\"user_input\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n","    template=template_hira\n",")"]},{"cell_type":"markdown","source":["**Katakana**"],"metadata":{"id":"BUrIKdyVD4zl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"B68nPeWWO5UD"},"outputs":[],"source":["template_kata = \"\"\"\n","You will be given a formatted romanji string from a user.\n","Printout its katakana by the given string.\n","\n","{format_instructions}\n","\n","% USER INPUT:\n","{user_input}\n","\n","YOUR RESPONSE:\n","\"\"\"\n","\n","# Embed our format description into prompt and tell llm what format we want him to output\n","prompt_kata = PromptTemplate(\n","    input_variables=[\"user_input\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n","    template=template_kata\n",")"]},{"cell_type":"code","source":["# if Kanji, prompt=prompt_kanji\n","# if Hiragana,prompt=prompt_hira\n","# if Katakana, prompt=prompt_kata\n","\n","promptValue = prompt.format(user_input= 'The Romanji Input')\n","llm_output = llm(promptValue)\n","t1_stop = time.time()\n","ime_string=output_parser.parse(llm_output).get(\"ime_string\")"],"metadata":{"id":"46ZZT432D8oI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PR_MmciuuEdr"},"source":["##### Prompt for Japanese Sentences\n","\n","\n","df=\"Japanese_Sentences\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nCWo__QjAB2b"},"outputs":[],"source":["response_schemas = [\n","    ResponseSchema(name=\"original_string\", description=\"This a formatted user input romanji string\"),\n","    ResponseSchema(name=\"ime_string\", description=\"This is your first response, the Japanese response\")\n","]\n","\n","#Initialization\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","\n","format_instructions = output_parser.get_format_instructions()\n","\n","template = \"\"\"\n","You will be given a formatted romanji string from a user.\n","Printout its Japaneses by the given string.\n","\n","{format_instructions}\n","\n","% USER INPUT:\n","{user_input}\n","\n","YOUR RESPONSE:\n","\"\"\"\n","\n","# Embed our format description into prompt and tell llm what format we want him to output\n","prompt = PromptTemplate(\n","    input_variables=[\"user_input\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n","    template=template)"]},{"cell_type":"code","source":["\"\"\"Mistral Model\"\"\"\n","### Define the ***Prompt Template for Mistral\n","\n","messages = [\n","    (\"system\", \"\"\"\n","    Please convert the provided Romanji input into its most accurate corresponding Japanese characters.\n","    \"\"\"),\n","    (\"human\", \"\"\"\n","    {format_instructions}\n","\n","    % USER INPUT:\n","    {user_input}\n","\n","    YOUR RESPONSE:\n","    \"\"\")\n","]\n","\n","# Configure Prompt and Chain (using LCEL)\n","prompt = ChatPromptTemplate.from_messages(messages)\n"],"metadata":{"id":"zNFaxd9q0ow_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1GYkV-dlIjOU"},"source":["### Textual Error Correction\n","\n"]},{"cell_type":"code","source":["\n","model_name=\"gpt-4o\"/\"gpt4-turbo\"/\"gpt3.5-turbo\"\n","\n","llm = OpenAIChat(model_name=\"gpt-4o\",temperature=0)\n"],"metadata":{"id":"V2xGAT3gGfzg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KF--SPHS4Rpo"},"source":["#### Chinese"]},{"cell_type":"markdown","metadata":{"id":"IqELC-6vFD5u"},"source":["##### Pinyin-based Error Prompt"]},{"cell_type":"code","source":["response_schemas = [\n","    ResponseSchema(name=\"original_string\", description=\"This an incorrect user input Pinyin sentence\"),\n","    ResponseSchema(name=\"corrected_string\", description=\"This is your first response, the correct Chinese response\")\n","]\n","\n","#Initialization\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","format_instructions = output_parser.get_format_instructions()\n"],"metadata":{"id":"KGQMerJbK9ga"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jfb2CEqiC51c"},"outputs":[],"source":["# Prompt for Template\n","template = \"\"\"\n","You will be given strings with incorrect Pinyin from a user,  which may contain\n","some numbers, various kinds of typos including missing and adding some letters,\n","mispress nearby letter keys,  and etc.\n","\n","Typo Examples:\n","\n","Input: \"ni hai ma?\"\n","Error: \"hai\" should be \"hao\"\n","Corrected Pinyin: \"ni hao ma?\"\n","Output Chinese: \"你好吗?\"\n","\n","Input: \"zhee shi wo de sh.\"\n","Error: \"zhee\" should be \"zhe\"; \"sh\" should \"shu\"\n","Corrected Pinyin: \"zhe shi wo de shu.\"\n","Output Chinese: \"这是我的书.\"\n","\n","Input: \"ta s wo de peng you.\"\n","Error: \"s\" should be \"shi\"\n","Corrected Pinyin: \"ta shi wo de pengyou.\"\n","Output Chinese: \"他是我的朋友.\"\n","\n","Input: \"qianmian yu yi jia diai.\"\n","Error: \"yu\" should be \"you\";\"diai\" should be \"dian\"\n","Corrected Pinyin: \"qianmian you yi jia dian.\"\n","Output Chinese: \"前面有一家店.\"\n","\n","Try to correct the Pinyin and output the corresponding Chinese.\n","\n","{format_instructions}\n","\n","% USER INPUT:\n","{user_input}\n","\n","YOUR RESPONSE:\n","\"\"\"\n","\n","\n","\n","# Embed our format description into prompt and tell llm what format we want him to output\n","prompt = PromptTemplate(\n","    input_variables=[\"user_input\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n","    template=template\n",")\n","promptValue = prompt.format(user_input= \"noise Pinyin input\")\n","llm_output = llm (promptValue)\n","output_parser.parse(llm_output).get(\"corrected_string\")"]},{"cell_type":"code","source":["\"\"\"Mistral Model\"\"\"\n","\n","messages = [\n","    (\"system\", \"\"\"\n","      You will be given strings with incorrect Pinyin from a user,  which may contain\n","      some numbers, various kinds of typos including missing and adding some letters,\n","      mispress nearby letter keys,  and etc.\n","\n","      Typo Examples:\n","\n","      Input: \"ni hai ma?\"\n","      Error: \"hai\" should be \"hao\"\n","      Corrected Pinyin: \"ni hao ma?\"\n","      Output Chinese: \"你好吗?\"\n","\n","      Input: \"zhee shi wo de sh.\"\n","      Error: \"zhee\" should be \"zhe\"; \"sh\" should \"shu\"\n","      Corrected Pinyin: \"zhe shi wo de shu.\"\n","      Output Chinese: \"这是我的书.\"\n","\n","      Input: \"ta s wo de peng you.\"\n","      Error: \"s\" should be \"shi\"\n","      Corrected Pinyin: \"ta shi wo de pengyou.\"\n","      Output Chinese: \"他是我的朋友.\"\n","\n","      Input: \"qianmian yu yi jia diai.\"\n","      Error: \"yu\" should be \"you\";\"diai\" should be \"dian\"\n","      Corrected Pinyin: \"qianmian you yi jia dian.\"\n","      Output Chinese: \"前面有一家店.\"\n","\n","      Try to correct the Pinyin and output the corresponding Chinese.\n","    \"\"\"),\n","    (\"human\", \"\"\"\n","    {format_instructions}\n","\n","    % USER INPUT:\n","    {user_input}\n","\n","    YOUR RESPONSE:\n","    \"\"\")\n","]\n","\n","# Configure Prompt and Chain (using LCEL)\n","prompt = ChatPromptTemplate.from_messages(messages)\n","chain = prompt | mistral | output_parser\n","\n","# Invoke the chain\n","response = chain.invoke({\"user_input\": \"The Pinyin Input\", \"format_instructions\": format_instructions})\n","\n","# Print the corresponding Chinese characters from \"corrected_string\"\n","response.get(\"corrected_string\", \"No corrected_string found\")\n"],"metadata":{"id":"MFpFkRWz1P-x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9xDGoqblEyK5"},"source":["##### Chinese Character-based Error Prompt"]},{"cell_type":"code","source":["response_schemas = [\n","    ResponseSchema(name=\"original_string\", description=\"This an incorrect user input Chinese sentence\"),\n","    ResponseSchema(name=\"corrected_string\", description=\"This is your first response, the correct Chinese response\")\n","]\n","\n","#Initialization\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","\n","format_instructions = output_parser.get_format_instructions()\n"],"metadata":{"id":"wNox-ATNLC3I"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9G7pKZHUUTZR"},"outputs":[],"source":["\"\"\"GPT and Claude Family\"\"\"\n","\n","# Prompt for Template\n","template = \"\"\"\n","You will be given sentences with incorrect Chinese characters from a user,  which\n","may contain some numbers, various kinds of errors including wrong characters with\n","typos, word misuse, grammatical errors, and more.\n","\n","Error Examples:\n","\n","Input: \"白血斌\"\n","Error: \"斌\" should be \"病\"\n","Corrected Chinese: \"白血病\"\n","\n","Input: \"我要去北京tiananman广场玩儿。\"\n","Error: \"tiananman\" should be \"天安门\"\n","Corrected Chinese: \"我要去北京天安门广场玩儿。\"\n","\n","Input: \"金秋9月，给大高校开学的钟声陆续敲响，全国各地先去了周边短租热潮\"\n","Error: \"给大\" should be \"各大\"; \"先去\" should \"掀起\"\n","Corrected Chinese: \"金秋9月，各大高校开学的钟声陆续敲响，全国各地掀起了周边短租热潮\"\n","\n","\n","Input: \"意味着这些第3方应用灭下来将无法向用户发送私\"\n","Error: \"灭下来\" should be “接下来\"; \"私\" should be \"私信\"\n","Corrected Chinese: \"意味着这些第3方应用接下来将无法向用户发送私信\"\n","\n","\n","Try to correct the wrong Chinese characters and output the corresponding correct Chinese sentence.\n","\n","{format_instructions}\n","\n","% USER INPUT:\n","{user_input}\n","\n","YOUR RESPONSE:\n","\"\"\"\n","\n","\n","\n","\n","\n","# Embed our format description into prompt and tell llm what format we want him to output\n","prompt = PromptTemplate(\n","    input_variables=[\"user_input\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n","    template=template\n",")\n","promptValue = prompt.format(user_input= \"noise Chinese character input\")\n","llm_output = llm (promptValue)\n","output_parser.parse(llm_output).get(\"corrected_string\")\n"]},{"cell_type":"code","source":["\"\"\"Mistral Model\"\"\"\n","\n","messages = [\n","    (\"system\", \"\"\"\n","      You will be given sentences with incorrect Chinese characters from a user,  which may contain some numbers, various kinds of\n","      errors including wrong characters with typos, word misuse, grammatical errors, and more.\n","\n","      Error Examples:\n","\n","      Input: \"白血斌\"\n","      Error: \"斌\" should be \"病\"\n","      Corrected Chinese: \"白血病\"\n","\n","      Input: \"我要去北京tiananman广场玩儿。\"\n","      Error: \"tiananman\" should be \"天安门\"\n","      Corrected Chinese: \"我要去北京天安门广场玩儿。\"\n","\n","      Input: \"金秋9月，给大高校开学的钟声陆续敲响，全国各地先去了周边短租热潮\"\n","      Error: \"给大\" should be \"各大\"; \"先去\" should \"掀起\"\n","      Corrected Chinese: \"金秋9月，各大高校开学的钟声陆续敲响，全国各地掀起了周边短租热潮\"\n","\n","\n","      Input: \"意味着这些第3方应用灭下来将无法向用户发送私\"\n","      Error: \"灭下来\" should be “接下来\"; \"私\" should be \"私信\"\n","      Corrected Chinese: \"意味着这些第3方应用接下来将无法向用户发送私信\"\n","\n","    Try to correct the wrong Chinese characters and output the corresponding correct Chinese sentence.\n","    \"\"\"),\n","    (\"human\", \"\"\"\n","    {format_instructions}\n","\n","    % USER INPUT:\n","    {user_input}\n","\n","    YOUR RESPONSE:\n","    \"\"\")\n","]\n","\n","\n","\n","# Configure Prompt and Chain (using LCEL)\n","prompt = ChatPromptTemplate.from_messages(messages)\n","chain = prompt | mistral | output_parser\n","\n","# Invoke the chain\n","response = chain.invoke({\"user_input\": \"The Pinyin Input\", \"format_instructions\": format_instructions})\n","# Print the corresponding Chinese characters from \"corrected_string\"\n","response.get(\"corrected_string\", \"No corrected_string found\")\n"],"metadata":{"id":"yeLgGClxzplV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wcA-a8WPzp1z"},"source":["#### Japanese"]},{"cell_type":"markdown","metadata":{"id":"r7_esmluzp10"},"source":["##### Romanji-based Error Prompt"]},{"cell_type":"code","source":["response_schemas = [\n","    ResponseSchema(name=\"original_string\", description=\"This an incorrect user input romanji sentence\"),\n","    ResponseSchema(name=\"corrected_string\", description=\"This is your first response, the correct Japanese response\")\n","]\n","\n","#Initialization\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","format_instructions = output_parser.get_format_instructions()\n"],"metadata":{"id":"nUPBhdo_zp10"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZlA3K2tpzp10"},"outputs":[],"source":["\"\"\" GPT and Claude Family\"\"\"\n","\n","template = \"\"\"\n","You will be given strings with incorrect Romanji from a user,  which may contain\n","various kinds of typos including missing or adding some letters, mispress or\n","substitute other characters, and grammatical errors and more.\n","\n","Typo Examples:\n","\n","Input: \"Ani ni butia shozoku\"\n","Error: \"no\" should be \"ni\";\"butia\" should be \"butai\"\n","Corrected Romanji: \"Ani no butai shozoku\"\n","Output Japanese: \"兄の部隊所属\"\n","\n","Input: \"amerika deha 20 seiki nakaba made hakujin no kayou gakkou to kokujin no kayou gakkou ni waka reita.\"\n","Error: \"reita\" should be \"reteita\"\n","Corrected Romanji: \"amerika deha 20 seiki nakaba made hakujin no kayou gakkou to kokujin no kayou gakkou ni waka reteita.\"\n","Output Japanese: \"アメリカでは20世紀半ばまで白人の通う学校と黒人の通う学校に分かれいた.\"\n","\n","Input: \"shikashii nyuujiirandokannpanii to imin ha uragiri dato kanji ta.\"\n","Error: \"shikashii\" should be \"shikashi\";\"nyuujiirandokannpanii\" should be \"nyuujiirandokanpanii\"\n","Corrected Romanji: \"shikashi nyuujiirandokanpanii to imin ha uragiri dato kanji ta.\"\n","Output Japanese: \"しかしニュージーランドカンパニーと移民は裏切りだと感じた.\"\n","\n","\n","\n","Try to correct the Romanji and output the corresponding Japaneses.\n","\n","{format_instructions}\n","\n","% USER INPUT:\n","{user_input}\n","\n","YOUR RESPONSE:\n","\"\"\"\n","\n","# Embed our format description into prompt and tell llm what format we want him to output\n","prompt = PromptTemplate(\n","    input_variables=[\"user_input\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n","    template=template\n",")\n","promptValue = prompt.format(user_input= \"noise Romanji input\")\n","llm_output = llm (promptValue)\n","output_parser.parse(llm_output).get(\"corrected_string\")"]},{"cell_type":"code","source":["\"\"\" Mistral Model\"\"\"\n","\n","messages = [\n","    (\"system\", \"\"\"\n","    You will be given strings with incorrect Romanji from a user,  which may contain\n","    various kinds of typos including missing or adding some letters, mispress or\n","    substitute other characters, and grammatical errors and more.\n","\n","    Typo Examples:\n","\n","    Input: \"Ani ni butia shozoku\"\n","    Error: \"no\" should be \"ni\";\"butia\" should be \"butai\"\n","    Corrected Romanji: \"Ani no butai shozoku\"\n","    Output Japanese: \"兄の部隊所属\"\n","\n","    Input: \"amerika deha 20 seiki nakaba made hakujin no kayou gakkou to kokujin no kayou gakkou ni waka reita.\"\n","    Error: \"reita\" should be \"reteita\"\n","    Corrected Romanji: \"amerika deha 20 seiki nakaba made hakujin no kayou gakkou to kokujin no kayou gakkou ni waka reteita.\"\n","    Output Japanese: \"アメリカでは20世紀半ばまで白人の通う学校と黒人の通う学校に分かれいた.\"\n","\n","    Input: \"shikashii nyuujiirandokannpanii to imin ha uragiri dato kanji ta.\"\n","    Error: \"shikashii\" should be \"shikashi\";\"nyuujiirandokannpanii\" should be \"nyuujiirandokanpanii\"\n","    Corrected Romanji: \"shikashi nyuujiirandokanpanii to imin ha uragiri dato kanji ta.\"\n","    Output Japanese: \"しかしニュージーランドカンパニーと移民は裏切りだと感じた.\"\n","\n","    Try to correct the Romanji and output the corresponding Japaneses.\n","\n","    \"\"\"),\n","    (\"human\", \"\"\"\n","    {format_instructions}\n","\n","    % USER INPUT:\n","    {user_input}\n","\n","    YOUR RESPONSE:\n","    \"\"\")\n","]\n","\n","# Configure Prompt and Chain (using LCEL)\n","prompt = ChatPromptTemplate.from_messages(messages)\n","chain = prompt | model | output_parser\n","# Invoke the chain\n","response = chain.invoke({\"user_input\": \"The Pinyin Input\", \"format_instructions\": format_instructions})\n","\n","# Print the corresponding Chinese characters from \"corrected_string\"\n","response.get(\"corrected_string\", \"No corrected_string found\")\n"],"metadata":{"id":"8cOsfDWr1xGO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0fg9tiNgzp10"},"source":["##### Japanese Character-based Error Prompt"]},{"cell_type":"code","source":["response_schemas = [\n","    ResponseSchema(name=\"original_string\", description=\"This an incorrect user input Japanese sentence\"),\n","    ResponseSchema(name=\"corrected_string\", description=\"This is your first response, the correct Japanese response\")\n","]\n","\n","#Initialization\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","format_instructions = output_parser.get_format_instructions()\n"],"metadata":{"id":"TR5AqXtdzp10"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Xm6vEFOzp11"},"outputs":[],"source":["\"\"\" GPT and Claude Family\"\"\"\n","\n","# Prompt for Template\n","template = \"\"\"\n","You will be given sentences with incorrect Japanese characters from a user, which\n","may contain various kinds of errors including replacement of a character with an\n","erroneous one,the omission of a necessary character, the addition of an\n","unnecessary character, and character misuse, grammatical errors, and more.\n","\n","Error Examples:\n","\n","Input: \"全学全てが大学院に以降していないため。\"\n","Error: \"以降\" should be \"移行\"\n","Corrected Japanese: \"全学全てが大学院に移行していないため。\"\n","\n","Input: \"兄弟がいないため、兄弟の多い六助を羨ましいと思ってる節がある。\"\n","Error: \"てる\" should be \"ている\"\n","Corrected Japanese: \"兄弟がいないため、兄弟の多い六助を羨ましいと思っている節がある。\"\n","\n","Input: \"そして転校初日に校舎裏に呼び出さる。\"\n","Error: \"る\" should be \"れる\"\n","Corrected Japanese: \"そして転校初日に校舎裏に呼び出される。\"\n","\n","\n","Try to correct the wrong Japanses characters and output the corresponding correct Japanese sentence.\n","\n","{format_instructions}\n","\n","% USER INPUT:\n","{user_input}\n","\n","YOUR RESPONSE:\n","\"\"\"\n","\n","\n","# Embed our format description into prompt and tell llm what format we want him to output\n","prompt = PromptTemplate(\n","    input_variables=[\"user_input\"],\n","    partial_variables={\"format_instructions\": format_instructions},\n","    template=template\n",")\n","promptValue = prompt.format(user_input= \"noise Chinese character input\")\n","llm_output = llm (promptValue)\n","output_parser.parse(llm_output).get(\"corrected_string\")"]},{"cell_type":"code","source":["\"\"\" Mistral Model\"\"\"\n","\n","messages = [\n","    (\"system\", \"\"\"\n","      You will be given sentences with incorrect Japanese characters from a user, which\n","      may contain various kinds of errors including replacement of a character with an\n","      erroneous one,the omission of a necessary character, the addition of an\n","      unnecessary character, and character misuse, grammatical errors, and more.\n","\n","      Error Examples:\n","\n","      Input: \"全学全てが大学院に以降していないため。\"\n","      Error: \"以降\" should be \"移行\"\n","      Corrected Japanese: \"全学全てが大学院に移行していないため。\"\n","\n","      Input: \"兄弟がいないため、兄弟の多い六助を羨ましいと思ってる節がある。\"\n","      Error: \"てる\" should be \"ている\"\n","      Corrected Japanese: \"兄弟がいないため、兄弟の多い六助を羨ましいと思っている節がある。\"\n","\n","      Input: \"そして転校初日に校舎裏に呼び出さる。\"\n","      Error: \"る\" should be \"れる\"\n","      Corrected Japanese: \"そして転校初日に校舎裏に呼び出される。\"\n","\n","\n","      Try to correct the wrong Japanses characters and output the corresponding correct Japanese sentence.\n","    \"\"\"),\n","    (\"human\", \"\"\"\n","    {format_instructions}\n","\n","    % USER INPUT:\n","    {user_input}\n","\n","    YOUR RESPONSE:\n","    \"\"\")\n","]\n","\n","# Configure Prompt and Chain (using LCEL)\n","prompt = ChatPromptTemplate.from_messages(messages)\n","chain = prompt | model | output_parser\n","# Invoke the chain\n","response = chain.invoke({\"user_input\": \"The Pinyin Input\", \"format_instructions\": format_instructions})\n","\n","# Print the corresponding Chinese characters from \"corrected_string\"\n","response.get(\"corrected_string\", \"No corrected_string found\")\n"],"metadata":{"id":"zqGlSeB917Qa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"niM3j0TIOSsl"},"source":["## Qwen2 Model(Only for Chinese)\n","\n","***We can use langchain for Qwen2 Model or not use langchain for it. If use langchain, it is similar with GPT,Claude and Mistral Model***\n","\n","**Reminder： The Prompt Instruction of Qwen2 model supports English and Chinese.**"]},{"cell_type":"markdown","source":["#### ***langchain***\n","\n","All other task prompt template is same with above."],"metadata":{"id":"_0BvNoxF6uDX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mhQ4UvfO6ZSR"},"outputs":[],"source":["\"\"\"Langchain\"\"\"\n","# Define the response schemas\n","response_schemas = [\n","    ResponseSchema(name=\"original_string\", description=\"This is a user input Pinyin string\"),\n","    ResponseSchema(name=\"ime_string\", description=\"This is your first response, the Chinese response\")\n","]\n","\n","\n","# Initialize the output parser\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","\n","# Get the format instructions\n","format_instructions = output_parser.get_format_instructions()\n","\n","# Define the prompt template\n","template = \"\"\"\n","You will be given a Pinyin with tone from a user, try to output the corresponding Chinese.\n","\n","{format_instructions}\n","\n","% USER INPUT:\n","{user_input}\n","\n","YOUR RESPONSE:\n","\"\"\"\n","\n","\n","\n","final_prompt = prompt.format(user_input=\"The Pinyin Input\")\n","# Define the messages for the chat model\n","messages = [\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": final_prompt}\n","]\n","\n","# Initialize the tokenizer and model\n","\n","# Apply the chat template using the tokenizer\n","text = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize=False,\n","    add_generation_prompt=True\n",")\n","\n","# Prepare the model inputs\n","model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n","\n","# Generate the response from the model\n","generated_ids = model.generate(\n","    model_inputs.input_ids,\n","    max_new_tokens=len(input),\n","    temperature = 0.2\n",")\n","generated_ids = [\n","    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n","]\n","\n","# Decode the response\n","response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n","# Parse the structured response\n","parsed_response = output_parser.parse(response)\n","parsed_response.get(\"ime_string\")"]},{"cell_type":"markdown","source":["***Following is another template which doesn't use langchain.***\n","\n","#### No langchain"],"metadata":{"id":"4Ocp7Yad7SDv"}},{"cell_type":"markdown","metadata":{"id":"mwvnr96exhA5"},"source":["##### Prompt for Chinese Words"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dWrUcLwUJ_2r"},"outputs":[],"source":["def qwen2_cw_generation(input, verbose=False):\n","  #Below is a combination of instructions describing the task and input with context. Given a response that appropriately meets the instructions.\n","\n","  ### English Version\n","  \"\"\"\n","    try:\n","      instruction = \"Convert the given Pinyin with tones into the most accurate corresponding Chinese characters.\"\n","      prompt=f\"\"\"\n","\n","      ### instruction:\n","      {instruction}\n","\n","      ### input:\n","      {input}\n","\n","      ### response:\n","      \"\"\"\n","  \"\"\"\n","  ### Chinese Version\n","    try:\n","      instruction = \"将给定的带声调拼音转换为最准确对应的中文字符。\"\n","      prompt = f\"\"\"\n","\n","      ### 指令:\n","      {instruction}\n","\n","      ### 输入:\n","      {input}\n","\n","      ### 回答:\n","      \"\"\"\n","\n","\n","      token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n","\n","      with torch.no_grad():\n","          output_ids = model.generate(\n","              token_ids.to(model.device),\n","              max_new_tokens=50,\n","              do_sample=True,\n","              temperature=0.2,\n","              pad_token_id=tokenizer.pad_token_id,\n","              bos_token_id=tokenizer.bos_token_id,\n","              eos_token_id=tokenizer.eos_token_id\n","          )\n","\n","      output = tokenizer.decode(output_ids.tolist()[0])\n","\n","      if verbose:\n","        print(output)\n","\n","      #return output.split(\"### response:\\n\")[1].split(\"\\n\")[0].strip()\n","      return output.split(\"### 回答:\\n\")[1].split(\"\\n\")[0].strip()\n","  except:\n","      return '';"]},{"cell_type":"markdown","metadata":{"id":"3iJfSoJgs-0S"},"source":["##### Prompt for Chinese Sentences"]},{"cell_type":"markdown","source":["***Simplified Version***"],"metadata":{"id":"a_3he46U__XH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cu_ijvWpSfUC"},"outputs":[],"source":["def qwen2_cs_generation_simp(input, verbose=False):\n","  #Below is a combination of instructions describing the task and input with context. Given a response that appropriately meets the instructions.\n","\n","  ### English Version\n","  '''\n","  try:\n","      instruction = \"Convert the given Pinyin into the most accurate corresponding Simplified Chinese characters.\"\n","      prompt=f\"\"\"\n","\n","      ### instruction:\n","      {instruction}\n","\n","      ### input:\n","      {input}\n","\n","      ### response:\n","      \"\"\"\n","  '''\n","  ## Chinese Version\n","  try:\n","      instruction = \"将给定的带声调拼音转换为最准确对应的简体中文字符。\"\n","      prompt = f\"\"\"\n","\n","      ### 指令:\n","      {instruction}\n","\n","      ### 输入:\n","      {input}\n","\n","      ### 回答:\n","    \"\"\"\n","\n","\n","\n","      token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n","\n","      with torch.no_grad():\n","          output_ids = model.generate(\n","              token_ids.to(model.device),\n","              max_new_tokens=200,\n","              do_sample=True,\n","              pad_token_id=tokenizer.pad_token_id,\n","              bos_token_id=tokenizer.bos_token_id,\n","              eos_token_id=tokenizer.eos_token_id\n","          )\n","\n","      output = tokenizer.decode(output_ids.tolist()[0])\n","\n","      if verbose:\n","        print(output)\n","\n","      #return output.split(\"### response:\\n\")[1].split(\"\\n\")[0].strip()\n","      return output.split(\"### 回答:\\n\")[1].split(\"\\n\")[0].strip()\n","  except:\n","      return '';"]},{"cell_type":"markdown","source":["***Traditional Version***"],"metadata":{"id":"hQeldyDLADgF"}},{"cell_type":"code","source":["def qwen2_cs_generation_trad(input, verbose=False):\n","  #Below is a combination of instructions describing the task and input with context. Given a response that appropriately meets the instructions.\n","\n","  ### English Version\n","  '''\n","  try:\n","      instruction = \"Convert the given Pinyin into the most accurate corresponding Traditional Chinese characters.\"\n","      prompt=f\"\"\"\n","\n","      ### instruction:\n","      {instruction}\n","\n","      ### input:\n","      {input}\n","\n","      ### response:\n","      \"\"\"\n","  '''\n","  ## Chinese Version\n","  try:\n","      instruction = \"将给定的带声调拼音转换为最准确对应的繁体中文字符。\"\n","      prompt = f\"\"\"\n","\n","      ### 指令:\n","      {instruction}\n","\n","      ### 输入:\n","      {input}\n","\n","      ### 回答:\n","    \"\"\"\n","\n","      token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n","\n","      with torch.no_grad():\n","          output_ids = model.generate(\n","              token_ids.to(model.device),\n","              max_new_tokens=200,\n","              do_sample=True,\n","              pad_token_id=tokenizer.pad_token_id,\n","              bos_token_id=tokenizer.bos_token_id,\n","              eos_token_id=tokenizer.eos_token_id\n","          )\n","\n","      output = tokenizer.decode(output_ids.tolist()[0])\n","\n","      if verbose:\n","        print(output)\n","\n","      #return output.split(\"### response:\\n\")[1].split(\"\\n\")[0].strip()\n","      return output.split(\"### 回答:\\n\")[1].split(\"\\n\")[0].strip()\n","  except:\n","      return '';"],"metadata":{"id":"lPQQjJGAAHOQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kdCR69EuHP39"},"source":["##### Prompt for Chinese Sentence Correction"]},{"cell_type":"markdown","metadata":{"id":"NbuRBYn_jtOL"},"source":["###### Incorrect Pinyin"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HA5j38LLqgnT"},"outputs":[],"source":["def qwen2_csc_pinyinn(input, verbose=False):\n","    try:\n","\n","      prompt=f\"\"\"\n","      以下输入的拼音字符不正确，其中可能包括缺失或多余的字母、按错的键或放错的数字等拼写错误。\n","\n","      尝试纠正给定的错误拼音输入，并输出与之对应的最准确的中文。\n","\n","      ### 输入:\n","      {input}\n","\n","      ### 回答:\n","      \"\"\"\n","\n","\n","      token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n","\n","      with torch.no_grad():\n","          output_ids = model.generate(\n","              token_ids.to(model.device),\n","              max_new_tokens=len(input),\n","              do_sample=True,\n","              temperature=1,\n","              pad_token_id=tokenizer.pad_token_id,\n","              bos_token_id=tokenizer.bos_token_id,\n","              eos_token_id=tokenizer.eos_token_id\n","          )\n","\n","      output = tokenizer.decode(output_ids.tolist()[0])\n","\n","      if verbose:\n","        print(output)\n","\n","      return output.split(\"### 回答:\\n\")[1].split(\"\\n\")[0].strip().strip(\"<|im_end|>\")\n","   except:\n","      return '';\n","\n","#English Version\n","'''\n"," try:\n","      instruction =\"Correct the given Pinyin input and output the most accurate corresponding Chinese characters.\"\n","      prompt=f\"\"\"\n","\n","      You are provided with incorrect Pinyin, which may include typos\n","      such as missing or extra letters, mispressed keys, or misplaced numbers.\n","\n","\n","      ### instruction:\n","      {instruction}\n","\n","      ### input:\n","      {input}\n","\n","      ### response:\n","      \"\"\"\n","\n","  '''"]},{"cell_type":"markdown","metadata":{"id":"N2_nOUjtjzRo"},"source":["###### Incorrect Chinese Characters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q2a31eEyj1-D"},"outputs":[],"source":["def qwen2_csc_incorrectstrings(input, verbose=False):\n","  try:\n","\n","      prompt=f\"\"\"\n","      以下输入的中文字符不正确，其中可能包括语法错误，缺失或多余的字母、按错的键或放错的数字等拼写错误。\n","\n","      尝试纠正输入错误的中文字符。\n","\n","      ### 输入:\n","      {input}\n","\n","      ### 回答:\n","      \"\"\"\n","\n","      token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n","\n","      with torch.no_grad():\n","          output_ids = model.generate(\n","              token_ids.to(model.device),\n","              max_new_tokens=1.5*len(input),\n","              temperature=0.2,\n","              pad_token_id=tokenizer.pad_token_id,\n","              bos_token_id=tokenizer.bos_token_id,\n","              eos_token_id=tokenizer.eos_token_id\n","          )\n","\n","      output = tokenizer.decode(output_ids.tolist()[0])\n","\n","      if verbose:\n","        print(output)\n","\n","      return output.split(\"### 回答:\\n\")[1].split(\"\\n\")[0].strip().strip(\"<|im_end|>\")\n","  except:\n","      return '';\n","\n","#English Version\n","'''\n","  try:\n","      instruction =\"Correct the given erroneous Chinese input and output the most accurate corresponding Chinese characters.\"\n","      prompt=f\"\"\"\n","\n","      You are provided with incorrect Chinese characters, which may include typos\n","      such as missing or extra letters, mispressed keys, or misplaced numbers.\n","\n","      ### instruction:\n","      {instruction}\n","\n","      ### input:\n","      {input}\n","\n","      ### response:\n","      \"\"\"\n","\n","'''"]},{"cell_type":"markdown","metadata":{"id":"1coKd6KjQAgN"},"source":["Kanji"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"18jio0j-QAgO"},"outputs":[],"source":["def rn_jw_kanji_generation(input, verbose=False):\n","  try:\n","    instruction = \"ローマ字を日本語の漢字に変換してください。可能な限り正確に翻訳してください。\"\n","    prompt = f\"\"\"\n","    以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。ローマ字入力を日本語の漢字に正確に変換します。\n","\n","    ### 指示:\n","    {instruction}\n","\n","    ### 入力:\n","    {input}\n","\n","    ### 応答:\n","    \"\"\"\n","\n","    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n","\n","    with torch.no_grad():\n","        output_ids = model.generate(\n","            token_ids.to(model.device),\n","            max_new_tokens=100,\n","            do_sample=True,\n","            temperature=0.2,\n","            pad_token_id=tokenizer.pad_token_id,\n","            bos_token_id=tokenizer.bos_token_id,\n","            eos_token_id=tokenizer.eos_token_id\n","        )\n","\n","    output = tokenizer.decode(output_ids.tolist()[0])\n","    output = tokenizer.decode(output_ids.tolist()[0])\n","    #print(output)\n","    if verbose:\n","      print(output)\n","\n","    return output.replace(\"<|endoftext|>\", \"\").split(\"### 応答:\\n\")[1].split(\"\\n\")[0].strip()\n","  except:\n","    return '';"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":891,"status":"ok","timestamp":1742658208684,"user":{"displayName":"z yc","userId":"00246575246731476272"},"user_tz":240},"id":"MYnnTA8oQAgO","outputId":"6921c29a-28ae-4ce6-db23-ef5695f7986a"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'カレハは実家から離れた場所で仕事を始める。'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["rn_jw_kanji_generation(\"kareha shigoto notamenisono konsaato he ike nakatta.\")\n","#rn_jw_kanji_generation(\"akarasama\")"]},{"cell_type":"markdown","metadata":{"id":"F2Cg0CT6QAgO"},"source":["Hiragana"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wFR54LeRQAgO"},"outputs":[],"source":["def rn_jw_hira_generation(input, verbose=False):\n","  try:\n","    instruction = \"ローマ字入力を正確にひらがなに変換。可能な限り正確に翻訳してください。\"\n","    prompt = f\"\"\"\n","    以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。ローマ字入力を正確にひらがなに変換。\n","\n","    ### 指示:\n","    {instruction}\n","\n","    ### 入力:\n","    {input}\n","\n","    ### 応答:\n","    \"\"\"\n","\n","    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n","\n","    with torch.no_grad():\n","        output_ids = model.generate(\n","            token_ids.to(model.device),\n","            max_new_tokens=100,\n","            do_sample=True,\n","            temperature=0.2,\n","            pad_token_id=tokenizer.pad_token_id,\n","            bos_token_id=tokenizer.bos_token_id,\n","            eos_token_id=tokenizer.eos_token_id\n","        )\n","\n","    output = tokenizer.decode(output_ids.tolist()[0])\n","\n","    if verbose:\n","      print(output)\n","\n","    return output.replace(\"<|endoftext|>\", \"\").split(\"### 応答:\\n\")[1].split(\"\\n\")[0].strip()\n","  except:\n","    return '';"]},{"cell_type":"markdown","metadata":{"id":"vIFONLBhQAgP"},"source":["Katagana"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p8KbglMkQAgP"},"outputs":[],"source":["def rn_jw_kata_generation(input, verbose=False):\n","  try:\n","    instruction = \"ローマ字入力を正確にカタカナに変換します。可能な限り正確に翻訳してください。\"\n","    prompt = f\"\"\"\n","    以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。ローマ字入力を正確にカタカナに変換します。\n","\n","    ### 指示:\n","    {instruction}\n","\n","    ### 入力:\n","    {input}\n","\n","    ### 応答:\n","    \"\"\"\n","\n","    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n","\n","    with torch.no_grad():\n","        output_ids = model.generate(\n","            token_ids.to(model.device),\n","            max_new_tokens=100,\n","            do_sample=True,\n","            temperature=0.2,\n","            pad_token_id=tokenizer.pad_token_id,\n","            bos_token_id=tokenizer.bos_token_id,\n","            eos_token_id=tokenizer.eos_token_id\n","        )\n","\n","    output = tokenizer.decode(output_ids.tolist()[0])\n","\n","    if verbose:\n","      print(output)\n","\n","    return output.replace(\"<|endoftext|>\", \"\").split(\"### 応答:\\n\")[1].split(\"\\n\")[0].strip()\n","  except:\n","    return '';"]},{"cell_type":"markdown","metadata":{"id":"2OqNBAqDhLRO"},"source":["case example for textual generation of Japanese"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eoj200FZgK8Y"},"outputs":[],"source":["#input = \"kareha shigoto notamenisono konsaato he ike nakatta.\"\n","def rn_js_generation(input):\n","  instruction = \"ローマ字を日本語に変換\"\n","  prompt = f\"\"\"\n","  以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n","\n","  ### 指示:\n","  {instruction}\n","\n","  ### 入力:\n","  {input}\n","\n","  ### 応答:\n","  \"\"\"\n","\n","  token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n","\n","  with torch.no_grad():\n","      output_ids = model.generate(\n","          token_ids.to(model.device),\n","          max_new_tokens=len(input),\n","          do_sample=True,\n","          temperature=1,\n","          pad_token_id=tokenizer.pad_token_id,\n","          bos_token_id=tokenizer.bos_token_id,\n","          eos_token_id=tokenizer.eos_token_id\n","      )\n","\n","  output = tokenizer.decode(output_ids.tolist()[0])\n","  return output.split(\"### 応答:\\n\")[1].strip(\"<|endoftext|>\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8291,"status":"ok","timestamp":1742655345245,"user":{"displayName":"z yc","userId":"00246575246731476272"},"user_tz":240},"id":"Ffi_IHHyP4kr","outputId":"9ad808b8-af93-4173-81e7-85a86073470f"},"outputs":[{"name":"stdout","output_type":"stream","text":["西田幾多郎は、自らの「学問上の動機」を次のように語っている。哲学者として、「私は特に実在の問題ということに興味を持っています。それは私にとっては人生の問題そのものであり、世界の問題そのものなのです」。西田幾多郎にとっての実在とは何か。それは「私は実在は本質の問題だと思います。実在は存在そのものというよりも本質そのものの問題だと思います」。実在の問題が、本質の問題である。実在とは、世界の問題ではなく人生の問題である、と西田幾多郎は語っている。西田幾多郎と友永威烈の対談のなかで、西田幾多郎は、実在が人生の問題であるという理由として「私は実在の問題ということを人生と直接に係わっていると思うからです。実在の問題ということは即ちその存在論を意味するものですからそれは私が如何にして\n"]}],"source":["text = \"西田幾多郎は、\"\n","token_ids = tokenizer.encode(text, add_special_tokens=False, return_tensors=\"pt\")\n","\n","with torch.no_grad():\n","    output_ids = model.generate(\n","        token_ids.to(model.device),\n","        max_new_tokens=200,\n","        min_new_tokens=200,\n","        do_sample=True,\n","        temperature=1.0,\n","        top_p=0.95,\n","        pad_token_id=tokenizer.pad_token_id,\n","        bos_token_id=tokenizer.bos_token_id,\n","        eos_token_id=tokenizer.eos_token_id\n","    )\n","\n","output = tokenizer.decode(output_ids.tolist()[0])\n","print(output)"]},{"cell_type":"markdown","metadata":{"id":"M9WxgTlCK-MO"},"source":["## Rinna and Rakuten Model for Japanese\n","\n","**Reminder： The Prompt Instruction of Rakuten model supports Japanases and CHinese.** Please use Japanese as the instruction to launch model."]},{"cell_type":"markdown","metadata":{"id":"TdbfskutOJR5"},"source":["##### Japanese Words"]},{"cell_type":"markdown","metadata":{"id":"QTtOgywvAYfq"},"source":["Kanji"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iGzRGh-QAYfq"},"outputs":[],"source":["def rn_jw_kanji_generation(input, verbose=False):\n","  try:\n","    instruction = \"ローマ字を日本語の漢字に変換してください。可能な限り正確に翻訳してください。\"\n","    prompt = f\"\"\"\n","    以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。ローマ字入力を日本語の漢字に正確に変換します。\n","\n","    ### 指示:\n","    {instruction}\n","\n","    ### 入力:\n","    {input}\n","\n","    ### 応答:\n","    \"\"\"\n","\n","    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n","\n","    with torch.no_grad():\n","        output_ids = model.generate(\n","            token_ids.to(model.device),\n","            max_new_tokens=100,\n","            do_sample=True,\n","            temperature=0.5,\n","            pad_token_id=tokenizer.pad_token_id,\n","            bos_token_id=tokenizer.bos_token_id,\n","            eos_token_id=tokenizer.eos_token_id\n","        )\n","\n","    output = tokenizer.decode(output_ids.tolist()[0])\n","    output = tokenizer.decode(output_ids.tolist()[0])\n","    #print(output)\n","    if verbose:\n","      print(output)\n","\n","    return output.replace(\"<|endoftext|>\", \"\").split(\"### 応答:\\n\")[1].split(\"\\n\")[0].strip()\n","  except:\n","    return '';"]},{"cell_type":"markdown","metadata":{"id":"-xF0MaiAAYfr"},"source":["Hiragana"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u5IE-L8sAYfr"},"outputs":[],"source":["def rn_jw_hira_generation(input, verbose=False):\n","  try:\n","    instruction = \"ローマ字入力を正確にひらがなに変換。可能な限り正確に翻訳してください。\"\n","    prompt = f\"\"\"\n","    以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。ローマ字入力を正確にひらがなに変換。\n","\n","    ### 指示:\n","    {instruction}\n","\n","    ### 入力:\n","    {input}\n","\n","    ### 応答:\n","    \"\"\"\n","\n","    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n","\n","    with torch.no_grad():\n","        output_ids = model.generate(\n","            token_ids.to(model.device),\n","            max_new_tokens=100,\n","            do_sample=True,\n","            temperature=0.2,\n","            pad_token_id=tokenizer.pad_token_id,\n","            bos_token_id=tokenizer.bos_token_id,\n","            eos_token_id=tokenizer.eos_token_id\n","        )\n","\n","    output = tokenizer.decode(output_ids.tolist()[0])\n","\n","    if verbose:\n","      print(output)\n","\n","    return output.replace(\"<|endoftext|>\", \"\").split(\"### 応答:\\n\")[1].split(\"\\n\")[0].strip()\n","  except:\n","    return '';"]},{"cell_type":"markdown","metadata":{"id":"h72XMWQyAYfr"},"source":["Katagana"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lODem12wAYfr"},"outputs":[],"source":["def rn_jw_kata_generation(input, verbose=False):\n","  try:\n","    instruction = \"ローマ字入力を正確にカタカナに変換します。可能な限り正確に翻訳してください。\"\n","    prompt = f\"\"\"\n","    以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。ローマ字入力を正確にカタカナに変換します。\n","\n","    ### 指示:\n","    {instruction}\n","\n","    ### 入力:\n","    {input}\n","\n","    ### 応答:\n","    \"\"\"\n","\n","    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n","\n","    with torch.no_grad():\n","        output_ids = model.generate(\n","            token_ids.to(model.device),\n","            max_new_tokens=100,\n","            do_sample=True,\n","            temperature=0.2,\n","            pad_token_id=tokenizer.pad_token_id,\n","            bos_token_id=tokenizer.bos_token_id,\n","            eos_token_id=tokenizer.eos_token_id\n","        )\n","\n","    output = tokenizer.decode(output_ids.tolist()[0])\n","\n","    if verbose:\n","      print(output)\n","\n","    return output.replace(\"<|endoftext|>\", \"\").split(\"### 応答:\\n\")[1].split(\"\\n\")[0].strip()\n","  except:\n","    return '';"]},{"cell_type":"markdown","metadata":{"id":"O-JIdUxuO6Jb"},"source":["##### Japanese Sentence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z0mvYsgRQVwa"},"outputs":[],"source":["def rn_js_generation(input, verbose=False):\n","  try:\n","    instruction = \"ローマ字を日本語の文字に変換してください。可能な限り正確に翻訳してください。\"\n","    prompt = f\"\"\"\n","    以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。ローマ字の入力を、日本語の文字に正確に変換してください。\n","\n","    ### 指示:\n","    {instruction}\n","\n","    ### 入力:\n","    {input}\n","\n","    ### 応答:\n","    \"\"\"\n","\n","\n","    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n","\n","    with torch.no_grad():\n","        output_ids = model.generate(\n","            token_ids.to(model.device),\n","            max_new_tokens=300,\n","            do_sample=True,\n","            temperature=0.9,\n","            pad_token_id=tokenizer.pad_token_id,\n","            bos_token_id=tokenizer.bos_token_id,\n","            eos_token_id=tokenizer.eos_token_id\n","        )\n","\n","    output = tokenizer.decode(output_ids.tolist()[0])\n","\n","    if verbose:\n","      print(output)\n","\n","    return output.replace(\"<|endoftext|>\", \"\").split(\"### 応答:\\n\")[1].split(\"\\n\")[0].strip()\n","  except:\n","    return '';"]},{"cell_type":"markdown","metadata":{"id":"wsor568bNuAa"},"source":["### Japanese Error Correction"]},{"cell_type":"markdown","metadata":{"id":"ObZU1Ql1N03u"},"source":["#### Incorrect Romanji"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lHqV5AxHK7hF"},"outputs":[],"source":["def rn_jsc_generation(input, verbose=False):\n","    try:\n","        instruction = \"ローマ字の誤りを修正し、正確に日本語の文字に変換してください。\"\n","        prompt = f\"\"\"\n","        以下は、誤ったローマ字を含む入力文字列であり、文字の欠落、追加、置換、印刷ミスや文法的な誤り\n","        が含まれている可能性があります。ローマ字を修正し、それを正確に日本語の文字に変換してください。\n","\n","        ### 指示:\n","        {instruction}\n","\n","        ### 入力:\n","        {input}\n","\n","        ### 応答:\n","        \"\"\"\n","\n","        token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\").to(model.device)\n","\n","        with torch.no_grad():\n","            output_ids = model.generate(\n","                token_ids,\n","                max_new_tokens=500,\n","                do_sample=True,\n","                temperature=0.9,  # Adjusted to your previous setting\n","                pad_token_id=tokenizer.eos_token_id,\n","                bos_token_id=tokenizer.bos_token_id,\n","                eos_token_id=tokenizer.eos_token_id\n","            )\n","\n","        output = tokenizer.decode(output_ids.tolist()[0], skip_special_tokens=True).strip()\n","\n","        if verbose:\n","            print(output)\n","\n","        # Extract and return only the response part\n","        return output.split(\"### 応答:\\n\")[1].split(\"\\n\")[0].strip()\n","\n","    except Exception as e:\n","        if verbose:\n","            print(f\"Error: {e}\")\n","        return ''\n"]},{"cell_type":"markdown","metadata":{"id":"CP1hILuKN5Q0"},"source":["#### Incorrect Japanese Characters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p-XqX_SZcoSn"},"outputs":[],"source":["def rn_jsc_char_generation(input, verbose=False):\n","  try:\n","\n","    instruction = \"不正確な日本語の文字を修正し、正確な日本語の文章を出力してください。\"\n","\n","    prompt = f\"\"\"\n","    以下は、不正確な日本語の文字を含むユーザーの入力文です。これには、文字の欠落、追加、誤字、置換、\n","    文法的な誤りなどが含まれている可能性があります。誤りを修正し、正しい日本語の文章を出力してください。\n","\n","    ### 指示:\n","    {instruction}\n","\n","    ### 入力:\n","    {input}\n","\n","    ### 応答:\n","    \"\"\"\n","\n","    token_ids = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\").to(model.device)\n","\n","    with torch.no_grad():\n","          output_ids = model.generate(\n","              token_ids,\n","              max_new_tokens=500,\n","              do_sample=True,\n","              temperature=0.9,  # Adjusted to your previous setting\n","              pad_token_id=tokenizer.eos_token_id,\n","              bos_token_id=tokenizer.bos_token_id,\n","              eos_token_id=tokenizer.eos_token_id\n","          )\n","\n","    output = tokenizer.decode(output_ids.tolist()[0], skip_special_tokens=True).strip()\n","\n","    if verbose:\n","        print(output)\n","\n","      # Extract and return only the response part\n","    return output.split(\"### 応答:\\n\")[1].split(\"\\n\")[0].strip()\n","\n","  except Exception as e:\n","      if verbose:\n","          print(f\"Error: {e}\")\n","      return ''"]},{"cell_type":"markdown","metadata":{"id":"5E3Iz_islY7a"},"source":["## Baseline Model(Current)"]},{"cell_type":"markdown","metadata":{"id":"K2dooSvvsdTX"},"source":["\n","\n","For Chinese, *pypinyin* package converts Chinese to Pinyin and *Pinyin2Hanzi* are rare pacakge that can achieve Pinyin to Chinese.\n","\n","Here we import *Pinyin2Hanzi* as one of baseline models for Chinese Phonetic-based (Pinyin) textual generation task.\n","\n","\n","### Pinyin2Hanzi for Chinese\n","(Words and Sentences)\n","\n","1. HMM Transformation \\\\\n","2. DAG Transformation \\\\\n","\n","\n","The github of Pinyin2Hanzi is:\n","https://github.com/letiantian/Pinyin2Hanzi"]},{"cell_type":"markdown","source":["#### HMM"],"metadata":{"id":"EOo6w7ZJ8XVz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"U_xwnsRWDMCs"},"outputs":[],"source":["import re, Pinyin2Hanzi\n","from Pinyin2Hanzi import is_pinyin,simplify_pinyin\n","from Pinyin2Hanzi import DefaultHmmParams,DefaultDagParams,dag\n","from Pinyin2Hanzi import viterbi\n","\n","\n","hmmparams = DefaultHmmParams()\n","pre = re.compile(u'[\\u4e00-\\u9fa5-\\，\\。]')\n","\n","for j in range(df.shape[0]):\n","\n","    t1_start=time.time()\n","    hmm = viterbi(hmm_params=hmmparams, observations=(simplify_pinyin(df.pinyin.iloc[j]).split()), path_num = 1)\n","\n","    for i,item in enumerate(hmm):\n","      df.P2H_HMM_gen.iloc[j] = ''.join(re.findall(pre, str(item.path)))\n","    t1_stop=time.time()\n","    df.P2H_HMM_time.iloc[j] = t1_stop - t1_start\n","    print(\"No\",j,\"HMM_gen\",df.P2H_HMM_gen.iloc[j])\n","    print(\"No\",j,\"HMM_time\",t1_stop - t1_start)"]},{"cell_type":"code","source":["'''\n","df=Chinese Sentence\n","'''\n","hmmparams = DefaultHmmParams()\n","pre = re.compile(u'[\\u4e00-\\u9fa5-\\，\\。]')\n","\n","for j in range(df.shape[0]):\n","  text=re.sub(r'\\d+','',simplify_pinyin(df.pinyin_nopun.iloc[j]))\n","\n","  t1_start=time.time()\n","  hmm = viterbi(hmm_params=hmmparams, observations=(text.split()), path_num = 1)\n","  for i,item in enumerate(hmm):\n","      df.P2H_HMM_gen.iloc[j] = ''.join(re.findall(pre, str(item.path)))\n","  t1_stop=time.time()"],"metadata":{"id":"A9nonYhI86Px"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### DAG"],"metadata":{"id":"JGpBlLWn8bQP"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xSzNGYp7EBtH","outputId":"f2044c4e-4132-41d7-e5f8-3ed5a4309b0b","collapsed":true},"outputs":[{"name":"stdout","output_type":"stream","text":["No 0 DAG_gen 笼子\n","No 0 DAG_time 0.000835418701171875\n","No 1 DAG_gen 完白\n","No 1 DAG_time 0.0004544258117675781\n","No 2 DAG_gen 诚邀\n","No 2 DAG_time 0.0004894733428955078\n","No 3 DAG_gen 辞去\n","No 3 DAG_time 0.0003657341003417969\n","No 4 DAG_gen 漂流\n","No 4 DAG_time 0.0003802776336669922\n","No 5 DAG_gen 枪手\n","No 5 DAG_time 0.0005044937133789062\n","No 6 DAG_gen 驾校\n","No 6 DAG_time 0.0004057884216308594\n","No 7 DAG_gen 神教\n","No 7 DAG_time 0.0004248619079589844\n","No 8 DAG_gen 说唱\n","No 8 DAG_time 0.0003712177276611328\n","No 9 DAG_gen 简评\n","No 9 DAG_time 0.0003509521484375\n","No 10 DAG_gen 干将\n","No 10 DAG_time 0.0003352165222167969\n","No 11 DAG_gen 巡查\n","No 11 DAG_time 0.00035119056701660156\n","No 12 DAG_gen 强忍\n","No 12 DAG_time 0.000362396240234375\n","No 13 DAG_gen 基金\n","No 13 DAG_time 0.00034236907958984375\n","No 14 DAG_gen 管制\n","No 14 DAG_time 0.0003509521484375\n","No 15 DAG_gen 小说\n","No 15 DAG_time 0.0005524158477783203\n","No 16 DAG_gen 但要\n","No 16 DAG_time 0.0004048347473144531\n","No 17 DAG_gen 户责\n","No 17 DAG_time 0.0004029273986816406\n","No 18 DAG_gen 海鲜\n","No 18 DAG_time 0.0003960132598876953\n","No 19 DAG_gen 偿付\n","No 19 DAG_time 0.0004410743713378906\n","No 20 DAG_gen 诚信\n","No 20 DAG_time 0.00042176246643066406\n","No 21 DAG_gen 官能\n","No 21 DAG_time 0.00041794776916503906\n","No 22 DAG_gen 浅淡\n","No 22 DAG_time 0.02925729751586914\n","No 23 DAG_gen 叉子\n","No 23 DAG_time 0.0004911422729492188\n","No 24 DAG_gen 墙壁\n","No 24 DAG_time 0.00038313865661621094\n","No 25 DAG_gen 干娘\n","No 25 DAG_time 0.0003352165222167969\n","No 26 DAG_gen 禁止\n","No 26 DAG_time 0.0003314018249511719\n","No 27 DAG_gen 学风\n","No 27 DAG_time 0.00034546852111816406\n","No 28 DAG_gen 新界\n","No 28 DAG_time 0.0003590583801269531\n","No 29 DAG_gen 殆尽\n","No 29 DAG_time 0.0003306865692138672\n","No 30 DAG_gen 角球\n","No 30 DAG_time 0.0003399848937988281\n","No 31 DAG_gen 航道\n","No 31 DAG_time 0.00035262107849121094\n","No 32 DAG_gen 策划\n","No 32 DAG_time 0.00035858154296875\n","No 33 DAG_gen 当作\n","No 33 DAG_time 0.0003643035888671875\n","No 34 DAG_gen 影城\n","No 34 DAG_time 0.00034499168395996094\n","No 35 DAG_gen 强压\n","No 35 DAG_time 0.0003402233123779297\n","No 36 DAG_gen 怎知\n","No 36 DAG_time 0.0003829002380371094\n","No 37 DAG_gen 小题\n","No 37 DAG_time 0.0006489753723144531\n","No 38 DAG_gen 温控\n","No 38 DAG_time 0.00040221214294433594\n","No 39 DAG_gen 拆确\n","No 39 DAG_time 0.0003638267517089844\n","No 40 DAG_gen 浸泡\n","No 40 DAG_time 0.0003421306610107422\n","No 41 DAG_gen 调制\n","No 41 DAG_time 0.00034546852111816406\n","No 42 DAG_gen 词语\n","No 42 DAG_time 0.00036454200744628906\n","No 43 DAG_gen 得当\n","No 43 DAG_time 0.000362396240234375\n","No 44 DAG_gen 湿度\n","No 44 DAG_time 0.0003676414489746094\n","No 45 DAG_gen 册查\n","No 45 DAG_time 0.0003306865692138672\n","No 46 DAG_gen 家常\n","No 46 DAG_time 0.00036978721618652344\n","No 47 DAG_gen 深恐\n","No 47 DAG_time 0.00036144256591796875\n","No 48 DAG_gen 射杀\n","No 48 DAG_time 0.00033855438232421875\n","No 49 DAG_gen 混饭\n","No 49 DAG_time 0.0003771781921386719\n","No 50 DAG_gen 耗资\n","No 50 DAG_time 0.0003650188446044922\n","No 51 DAG_gen 皮包骨\n","No 51 DAG_time 0.0003819465637207031\n","No 52 DAG_gen 民方言\n","No 52 DAG_time 0.00037169456481933594\n","No 53 DAG_gen 札记单\n","No 53 DAG_time 0.0007188320159912109\n","No 54 DAG_gen 毛茸茸\n","No 54 DAG_time 0.0004611015319824219\n","No 55 DAG_gen 风机口\n","No 55 DAG_time 0.00044536590576171875\n","No 56 DAG_gen 肉自杀\n","No 56 DAG_time 0.0004248619079589844\n","No 57 DAG_gen 国门儿\n","No 57 DAG_time 0.00043511390686035156\n","No 58 DAG_gen 石狮市\n","No 58 DAG_time 0.00041222572326660156\n","No 59 DAG_gen 系溜溜\n","No 59 DAG_time 0.00037384033203125\n","No 60 DAG_gen 合同书\n","No 60 DAG_time 0.00038623809814453125\n","No 61 DAG_gen 氧化汞\n","No 61 DAG_time 0.00041413307189941406\n","No 62 DAG_gen 附属国\n","No 62 DAG_time 0.0005278587341308594\n","No 63 DAG_gen 大通关\n","No 63 DAG_time 0.0004000663757324219\n","No 64 DAG_gen 剧中人\n","No 64 DAG_time 0.0003962516784667969\n","No 65 DAG_gen 片二糖\n","No 65 DAG_time 0.00035762786865234375\n","No 66 DAG_gen 更衣室\n","No 66 DAG_time 0.00036215782165527344\n","No 67 DAG_gen 文化宫\n","No 67 DAG_time 0.00037169456481933594\n","No 68 DAG_gen 艺术性\n","No 68 DAG_time 0.00038504600524902344\n","No 69 DAG_gen 老骨头\n","No 69 DAG_time 0.0003669261932373047\n","No 70 DAG_gen 槽头网\n","No 70 DAG_time 0.00034618377685546875\n","No 71 DAG_gen 可塑性\n","No 71 DAG_time 0.0003705024719238281\n","No 72 DAG_gen 打滚而\n","No 72 DAG_time 0.0005273818969726562\n","No 73 DAG_gen 看不过\n","No 73 DAG_time 0.00038933753967285156\n","No 74 DAG_gen 转圈自\n","No 74 DAG_time 0.0004050731658935547\n","No 75 DAG_gen 团体操\n","No 75 DAG_time 0.00036525726318359375\n","No 76 DAG_gen 追悼会\n","No 76 DAG_time 0.0003609657287597656\n","No 77 DAG_gen 纪念封\n","No 77 DAG_time 0.0003681182861328125\n","No 78 DAG_gen 可可豆\n","No 78 DAG_time 0.0003833770751953125\n","No 79 DAG_gen 大块头\n","No 79 DAG_time 0.0003809928894042969\n","No 80 DAG_gen 打先锋\n","No 80 DAG_time 0.0004315376281738281\n","No 81 DAG_gen 星期日\n","No 81 DAG_time 0.0003936290740966797\n","No 82 DAG_gen 回娘家\n","No 82 DAG_time 0.00038433074951171875\n","No 83 DAG_gen 旧大陆\n","No 83 DAG_time 0.0004048347473144531\n","No 84 DAG_gen 脏字而\n","No 84 DAG_time 0.0003619194030761719\n","No 85 DAG_gen 心头肉\n","No 85 DAG_time 0.0003581047058105469\n","No 86 DAG_gen 老干部\n","No 86 DAG_time 0.0003821849822998047\n","No 87 DAG_gen 大帽子\n","No 87 DAG_time 0.0003905296325683594\n","No 88 DAG_gen 十一月\n","No 88 DAG_time 0.00036716461181640625\n","No 89 DAG_gen 鹅毛山\n","No 89 DAG_time 0.0007588863372802734\n","No 90 DAG_gen 向上怕\n","No 90 DAG_time 0.0004069805145263672\n","No 91 DAG_gen 客家话\n","No 91 DAG_time 0.0003840923309326172\n","No 92 DAG_gen 机关炮\n","No 92 DAG_time 0.0003800392150878906\n","No 93 DAG_gen 厌恶单\n","No 93 DAG_time 0.0003933906555175781\n","No 94 DAG_gen 榨油条\n","No 94 DAG_time 0.00037479400634765625\n","No 95 DAG_gen 看加息\n","No 95 DAG_time 0.0003676414489746094\n","No 96 DAG_gen 袍子而\n","No 96 DAG_time 0.0003662109375\n","No 97 DAG_gen 无条件\n","No 97 DAG_time 0.00038623809814453125\n","No 98 DAG_gen 同义字\n","No 98 DAG_time 0.00039315223693847656\n","No 99 DAG_gen 根指数\n","No 99 DAG_time 0.0003654956817626953\n","No 100 DAG_gen 软骨头\n","No 100 DAG_time 0.0004868507385253906\n","No 101 DAG_gen 真心话\n","No 101 DAG_time 0.0003733634948730469\n","No 102 DAG_gen 一米线\n","No 102 DAG_time 0.00036144256591796875\n","No 103 DAG_gen 日全食\n","No 103 DAG_time 0.0003662109375\n","No 104 DAG_gen 水果糖\n","No 104 DAG_time 0.0003979206085205078\n","No 105 DAG_gen 恨不能\n","No 105 DAG_time 0.0003809928894042969\n","No 106 DAG_gen 眼睛单丝\n","No 106 DAG_time 0.0003752708435058594\n","No 107 DAG_gen 扶手武将\n","No 107 DAG_time 0.00037479400634765625\n","No 108 DAG_gen 段合不完\n","No 108 DAG_time 0.0004673004150390625\n","No 109 DAG_gen 经济合同\n","No 109 DAG_time 0.0005171298980712891\n","No 110 DAG_gen 渗透规勉\n","No 110 DAG_time 0.00038313865661621094\n","No 111 DAG_gen 结成进阶\n","No 111 DAG_time 0.0003833770751953125\n","No 112 DAG_gen 一祁阳体\n","No 112 DAG_time 0.00040721893310546875\n","No 113 DAG_gen 社会科学\n","No 113 DAG_time 0.0004322528839111328\n","No 114 DAG_gen 摸底颗粒\n","No 114 DAG_time 0.00037598609924316406\n","No 115 DAG_gen 杀人不眨眼\n","No 115 DAG_time 0.00039696693420410156\n","No 116 DAG_gen 对视部队人\n","No 116 DAG_time 0.0004010200500488281\n","No 117 DAG_gen 等边三角形\n","No 117 DAG_time 0.0004975795745849609\n","No 118 DAG_gen 姿势企鹅国\n","No 118 DAG_time 0.00042724609375\n","No 119 DAG_gen 人建中晚清\n","No 119 DAG_time 0.00043845176696777344\n","No 120 DAG_gen 阿拉伯国家\n","No 120 DAG_time 0.00042247772216796875\n","No 121 DAG_gen 骑鹤上扬州\n","No 121 DAG_time 0.0004107952117919922\n","No 122 DAG_gen 公读者参考\n","No 122 DAG_time 0.0004265308380126953\n","No 123 DAG_gen 哑巴吃黄连\n","No 123 DAG_time 0.0004165172576904297\n","No 124 DAG_gen 男女授受不亲\n","No 124 DAG_time 0.0005102157592773438\n","No 125 DAG_gen 闻名不如见面\n","No 125 DAG_time 0.00044417381286621094\n","No 126 DAG_gen 吉人自有天相\n","No 126 DAG_time 0.00043964385986328125\n","No 127 DAG_gen 班禅额尔德尼\n","No 127 DAG_time 0.00045037269592285156\n","No 128 DAG_gen 老虎头上搔痒\n","No 128 DAG_time 0.00045013427734375\n","No 129 DAG_gen 几十年如一日\n","No 129 DAG_time 0.00045228004455566406\n","No 130 DAG_gen 河水不犯井水\n","No 130 DAG_time 0.00041747093200683594\n","No 131 DAG_gen 如堕五里雾中\n","No 131 DAG_time 0.0004112720489501953\n","No 132 DAG_gen 求人不如求己\n","No 132 DAG_time 0.00042176246643066406\n","No 133 DAG_gen 反其道而行之\n","No 133 DAG_time 0.0005185604095458984\n","No 134 DAG_gen 气死人而肉白骨\n","No 134 DAG_time 0.0004570484161376953\n","No 135 DAG_gen 春蚕到死丝方尽\n","No 135 DAG_time 0.0004820823669433594\n"]}],"source":["'''\n","df=Chinese word\n","'''\n","dagparams = DefaultDagParams()\n","pre = re.compile(u'[\\u4e00-\\u9fa5-\\，\\。]')\n","\n","for j in range(df.shape[0]):\n","    t1_start=time.time()\n","    dagg = dag(dagparams, simplify_pinyin(df.pinyin.iloc[j]).split(), path_num = 1)\n","    for i,item in enumerate(dagg):\n","      df.P2H_DAG_gen.iloc[j] = ''.join(re.findall(pre, str(item.path)))\n","    t1_stop=time.time()\n","    df.P2H_DAG_time.iloc[j] = t1_stop - t1_start\n","    print(\"No\",j,\"DAG_gen\",df.P2H_DAG_gen.iloc[j])\n","    print(\"No\",j,\"DAG_time\",t1_stop - t1_start)\n"]},{"cell_type":"code","source":["'''\n","df=Chinese sentence\n","'''\n","dagparams = DefaultDagParams()\n","pre = re.compile(u'[\\u4e00-\\u9fa5-\\，\\。]')\n","\n","for j in range(df.shape[0]):\n","  text=re.sub(r'\\d+','',simplify_pinyin(df.pinyin_nopun.iloc[j]))\n","\n","  t1_start=time.time()\n","  dagg = dag(dagparams, text.split(), path_num = 1)\n","  for i,item in enumerate(dagg):\n","      df.P2H_HMM_gen.iloc[j] = ''.join(re.findall(pre, str(item.path)))\n","  t1_stop=time.time()"],"metadata":{"id":"u9gkToiQ9TuS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Gemini"],"metadata":{"id":"7W2D8JSL87id"}},{"cell_type":"markdown","source":["Used for both Gemini1.5 Flash and Gemini2.0 Flash"],"metadata":{"id":"nO2307QR9C3I"}},{"cell_type":"markdown","source":["### Chinese Word Generation"],"metadata":{"id":"mQpLNqQK9nR8"}},{"cell_type":"code","source":["f\"\"\"\n","Convert this pinyin: \"{pinyin}\" to the corresponding Chinese characters. Return just the characters.\n","\"\"\""],"metadata":{"id":"b6NsxkAk98w8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Chinese Sentence Generation"],"metadata":{"id":"E_0SCghy9sye"}},{"cell_type":"code","source":["f\"\"\"\n","Convert the provided pinyin to {chn_type} Chinese, return your results only, do not explain: {pinyin}\n","\"\"\""],"metadata":{"id":"eoZ8CSVJ99EE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Japanese Word Generation"],"metadata":{"id":"v02T8W609s51"}},{"cell_type":"code","source":["f\"\"\"\n","Convert this Romaji: \"{romanji}\" to Japanese {to}. Return just the Japanese {to}.\n","\"\"\""],"metadata":{"id":"8kZKw-4x99ar"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Japanese Sentence Generation"],"metadata":{"id":"BRh9vLj_9tAH"}},{"cell_type":"code","source":["f\"\"\"\n","Convert the Romaji sentence: \"{romanji}\" to Japanese. Return just the Japanese sentence.\n","\"\"\""],"metadata":{"id":"i38SWjHb99rc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Chinese Error Correction"],"metadata":{"id":"PIQy8YJc9tGn"}},{"cell_type":"markdown","source":["Pinyin Correction"],"metadata":{"id":"lhQ0Vx0E3IzH"}},{"cell_type":"code","source":["f\"\"\"\n","Correct and convert this pinyin sentence: \"{pinyin}\" to Chinese characters. Only return the Chinese sentence.\n","\"\"\""],"metadata":{"id":"SwtHnPFI99-g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Chinese Characters Correction"],"metadata":{"id":"bv4ADtya3Kzg"}},{"cell_type":"code","source":["f\"\"\"\n","Correct any errors in this Chinese sentence: \"{incorrectstring}\". Only return the corrected Chinese sentence.\n","\"\"\""],"metadata":{"id":"VlXIdXa6InIH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Japanese Error Correction"],"metadata":{"id":"sNSitYQG9tOR"}},{"cell_type":"markdown","source":["Romaji Correction"],"metadata":{"id":"KrYsiutN3OE6"}},{"cell_type":"code","source":["f\"\"\"\n","Correct and convert this Romaji sentence: \"{pinyin}\" to Japanese characters. Only return the Japanese sentence.\n","\"\"\""],"metadata":{"id":"DqYwFgse9-fr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Japanese Characters Correction"],"metadata":{"id":"4UDc6eO63Pt3"}},{"cell_type":"code","source":["f\"\"\"\n","Correct any errors in this Japanese sentence: \"{incorrectstring}\". Only return the corrected Japanese sentence.\n","\"\"\""],"metadata":{"id":"QQcqLj3NIn4c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Llama"],"metadata":{"id":"MBN6ZLPP-En9"}},{"cell_type":"markdown","source":["Used for both Llama3-8B and Llama3.2-3B\n"],"metadata":{"id":"aaz7trx2-EoE"}},{"cell_type":"markdown","source":["### Chinese Word Generation"],"metadata":{"id":"Wqb6mfLE-EoG"}},{"cell_type":"code","source":["f\"\"\"\n","Convert the following Chinese pinyin word: \"{pinyin}\" to the corresponding Chinese characters.\n","Only respond with the Chinese characters.\n","\n","Example:\n","user: ni hao\n","output: 你好\n","\"\"\""],"metadata":{"id":"mAkoY2Rc-EoH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Chinese Sentence Generation"],"metadata":{"id":"ZXT2mTTc-EoK"}},{"cell_type":"code","source":["f\"\"\"\n","Convert the following Chinese pinyin sentence: \"{pinyin}\" to {categ} Chinese.\n","Only respond with the {categ} Chinese sentence.\n","\"\"\""],"metadata":{"id":"i9OI4rot-EoK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Japanese Word Generation"],"metadata":{"id":"uTzrq8sx-EoK"}},{"cell_type":"code","source":["f\"\"\"\n","Convert the following Japanese romaji word: \"{romaji}\" to the corresponding Japanese {categ} characters.\n","Only respond with the Japanese characters.\n","\"\"\""],"metadata":{"id":"WEfuRspc-EoM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Japanese Sentence Generation"],"metadata":{"id":"Vsx7_4fO-EoM"}},{"cell_type":"code","source":["f\"\"\"\n","Convert the following Japanese romaji sentence: \"{romaji}\" to Japanese.\n","Only respond with the Japanese sentence.\n","\"\"\""],"metadata":{"id":"2r_sfAP1-EoN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Chinese Error Correction"],"metadata":{"id":"_RqqQT25-EoN"}},{"cell_type":"markdown","source":["Pinyin Correction"],"metadata":{"id":"7kutNym73cEy"}},{"cell_type":"code","source":["f\"\"\"\n","Correct errors and convert the following Chinese pinyin sentence: \"{pinyin}\" to Chinese.\n","Only respond with the Chinese sentence.\n","\"\"\""],"metadata":{"id":"_0OVgvOQ-EoP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Chinese Characters Correction"],"metadata":{"id":"E53KubAe3eTf"}},{"cell_type":"code","source":["f\"\"\"\n","Correct errors in the following Chinese sentence: \"{pinyin}\".\n","Only respond with the Chinese sentence.\n","\"\"\""],"metadata":{"id":"IhSFUGFx3gUn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Japanese Error Correction"],"metadata":{"id":"REXMCQeW-EoP"}},{"cell_type":"markdown","source":["Romaji Correction"],"metadata":{"id":"z-sV7xC83pbR"}},{"cell_type":"code","source":["f\"\"\"\n","Correct errors and convert the following Japanese romaji sentence: \"{romaji}\" to Japanese.\n","Only respond with the Japanese sentence.\n","\"\"\""],"metadata":{"id":"3LYZIt9g-EoQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Japanese Characters Correction"],"metadata":{"id":"MmJ8XRM53rne"}},{"cell_type":"code","source":["f\"\"\"\n","Correct errors in the following Japanese sentence: \"{romaji}\".\n","Only respond with the Japanese sentence.\n","\"\"\""],"metadata":{"id":"Ezw93nom3pNB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Baichuan"],"metadata":{"id":"GnBpUJtb-FDw"}},{"cell_type":"markdown","source":["### Chinese Word Generation"],"metadata":{"id":"--3q-xmX-FDy"}},{"cell_type":"code","source":["f\"\"\"\n","你会从用户输入拼音，发出相应的简体中文。\n","\n","```json\n","{{\n","  \"original_string\": string  // This is a user input Pinyin string\n","  \"ime_string\": string  // This is your first response, the Chinese response\n","}}```\n","\n","% 用户输入：\n","{user_input}\n","\n","% 你的响应：\n","\"\"\""],"metadata":{"id":"QMObNa72-FDz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Chinese Sentence Generation"],"metadata":{"id":"qgOUwXBq-FD0"}},{"cell_type":"code","source":["f\"\"\"\n","你会从用户输入拼音，发出相应的{chn_type}中文。\n","\n","```json\n","{{\n","  \"original_string\": string  // This is a user input Pinyin string\n","  \"ime_string\": string  // This is your first response, the Chinese response\n","}}```\n","\n","% 用户输入：\n","{user_input}\n","\n","% 你的响应：\n","\"\"\""],"metadata":{"id":"hNjkaSro-FD0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Chinese Error Correction"],"metadata":{"id":"KSq8VcWk-FD7"}},{"cell_type":"markdown","source":["Pinyin Correction"],"metadata":{"id":"1vDoLswkISWX"}},{"cell_type":"code","source":["\"\"\"\n","帮用户把可能有错误的中文拼音修正，然后翻译成汉字。你一定要只将修正的句子回答应。\n","\"\"\""],"metadata":{"id":"fr2NAm-NHupB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Chinese Character Correction"],"metadata":{"id":"BoWt67UKIYrS"}},{"cell_type":"code","source":["\"\"\"\n","帮用户把可能有错误的中文汉字修正。你一定要只将修正的句子回答应。\n","\"\"\""],"metadata":{"id":"eDgzfEyo-FD8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GLM4"],"metadata":{"id":"nSHmgaqGAxsd"}},{"cell_type":"markdown","source":["### Chinese Word Generation"],"metadata":{"id":"QM6uH9zvAxsk"}},{"cell_type":"code","source":["f\"\"\"\n","You will be given a Pinyin from a user, try to output the corresponding Simplified Chinese.\n","\n","The output should be a markdown code snippet formatted in the following schema,\n","including the leading and trailing \"```json\" and \"```\":\n","\n","```json\n","{{\n","  \"original_string\": string  // This is a user input Pinyin string\n","  \"ime_string\": string  // This is your first response, the Chinese response\n","}}```\n","\n","% USER INPUT:\n","{user_input}\n","\n","% YOUR RESPONSE:\n","\"\"\""],"metadata":{"id":"4vwOmyFWAxsm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Chinese Sentence Generation"],"metadata":{"id":"dJ0Y01WQAxsn"}},{"cell_type":"code","source":["f\"\"\"\n","You will be given a Pinyin from a user, try to output the corresponding {chn_type} Chinese.\n","\n","The output should be a markdown code snippet formatted in the following schema,\n","including the leading and trailing \"```json\" and \"```\":\n","\n","```json\n","{{\n","  \"original_string\": string  // This is a user input Pinyin string\n","  \"ime_string\": string  // This is your first response, the Chinese response\n","}}```\n","\n","% USER INPUT:\n","{user_input}\n","\n","% YOUR RESPONSE:\n","\"\"\""],"metadata":{"id":"VxquMQenAxso"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Japanese Word Generation"],"metadata":{"id":"JGdAZjFbAxso"}},{"cell_type":"code","source":["f\"\"\"\n","You will be given a romaji from a user, try to output the corresponding Japanese.\n","\n","The output should be a markdown code snippet formatted in the following schema,\n","including the leading and trailing \"```json\" and \"```\":\n","\n","```json\n","{{\n","  \"original_string\": string  // This is a user input romaji string\n","  \"ime_string\": string  // This is your first response, the Japanese response\n","}}```\n","\n","% USER INPUT:\n","{user_input}\n","\n","% YOUR RESPONSE:\n","\"\"\""],"metadata":{"id":"lHkMfp8_Axsp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Japanese Sentence Generation"],"metadata":{"id":"Aitd-L0PAxsq"}},{"cell_type":"code","source":["f\"\"\"\n","You will be given a romaji from a user, try to output the corresponding Japanese.\n","\n","The output should be a markdown code snippet formatted in the following schema,\n","including the leading and trailing \"```json\" and \"```\":\n","\n","```json\n","{{\n","  \"original_string\": string  // This is a user input romaji string\n","  \"ime_string\": string  // This is your first response, the Japanese response\n","}}```\n","\n","% USER INPUT:\n","{user_input}\n","\n","% YOUR RESPONSE:\n","\"\"\""],"metadata":{"id":"uAS3WkyCAxsq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Chinese Error Correction"],"metadata":{"id":"9lJsLw4tAxsr"}},{"cell_type":"markdown","source":["Pinyin Correction"],"metadata":{"id":"OoLcn07m4ILm"}},{"cell_type":"code","source":["f\"\"\"\n","You will be given a string of Chinese pinyin,  which may contain slight errors.\n","This includes various kinds of typos including missing letters, extra letters,\n","and keyboard mispresses according to nearby letter keys, etc.\n","\n","Typo Examples:\n","\n","Input: \"ni hai ma?\"\n","Error: \"hai\" should be \"hao\"\n","Corrected Pinyin: \"ni hao ma?\"\n","Output Chinese: \"你好吗?\"\n","\n","Input: \"zhee shi wo de sh.\"\n","Error: \"zhee\" should be \"zhe\"; \"sh\" should \"shu\"\n","Corrected Pinyin: \"zhe shi wo de shu.\"\n","Output Chinese: \"这是我的书.\"\n","\n","Input: \"ta s wo de peng you.\"\n","Error: \"s\" should be \"shi\"\n","Corrected Pinyin: \"ta shi wo de pengyou.\"\n","Output Chinese: \"他是我的朋友.\"\n","\n","Input: \"qianmian yu yi jia diai.\"\n","Error: \"yu\" should be \"you\";\"diai\" should be \"dian\"\n","Corrected Pinyin: \"qianmian you yi jia dian.\"\n","Output Chinese: \"前面有一家店.\"\n","\n","Try to correct the Pinyin and output the corresponding simplified Chinese.\n","Ensure the final output is a Chinese sentence, and directly comes from the pinyin.\n","\"\"\""],"metadata":{"id":"5dm5q7Q_Axss"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Chinese Characters Correction"],"metadata":{"id":"WYzudCSt4HyI"}},{"cell_type":"code","source":["f\"\"\"\n","You will be given sentences with incorrect Chinese characters from a user,\n","which may contain some numbers, various kinds of errors including wrong characters\n","with typos, word misuse, grammatical errors, and more.\n","\n","Error Examples:\n","\n","Input: \"白血斌\"\n","Error: \"斌\" should be \"病\"\n","Corrected Chinese: \"白血病\"\n","\n","Input: \"我要去北京tiananman广场玩儿。\"\n","Error: \"tiananman\" should be \"天安门\"\n","Corrected Chinese: \"我要去北京天安门广场玩儿。\"\n","\n","Input: \"金秋9月，给大高校开学的钟声陆续敲响，全国各地先去了周边短租热潮\"\n","Error: \"给大\" should be \"各大\"; \"先去\" should \"掀起\"\n","Corrected Chinese: \"金秋9月，各大高校开学的钟声陆续敲响，全国各地掀起了周边短租热潮\"\n","\n","\n","Input: \"意味着这些第3方应用灭下来将无法向用户发送私\"\n","Error: \"灭下来\" should be “接下来\"; \"私\" should be \"私信\"\n","Corrected Chinese: \"意味着这些第3方应用接下来将无法向用户发送私信\"\n","\n","\n","Try to correct the wrong Chinese characters and output the corresponding correct simplified Chinese sentence.\n","Ensure the final output is a Chinese sentence.\n","\"\"\""],"metadata":{"collapsed":true,"id":"d4VXxwEv4IyZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Japanese Error Correction"],"metadata":{"id":"NxA2Y2TzAxst"}},{"cell_type":"markdown","source":["Romaji Correction"],"metadata":{"id":"xGQSMxLn4cJw"}},{"cell_type":"code","source":["f\"\"\"\n","You will be given strings with incorrect Romanji from a user, which may contain\n","various kinds of typos including missing or adding some letters, mispress or\n","substitute other characters, and grammatical errors and more.\n","\n","Try to correct the Romanji and output the corresponding Japanese sentence.\n","\"\"\""],"metadata":{"id":"7q9o26iEAxst"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Japanese Characters Correction"],"metadata":{"id":"ysBCHhKm4d3f"}},{"cell_type":"code","source":["f\"\"\"\n","You will be given sentences with incorrect Japanese characters from a user, which\n","may contain various kinds of errors including replacement of a character with an\n","erroneous one,the omission of a necessary character, the addition of an\n","unnecessary character, and character misuse, grammatical errors, and more.\n","\n","Try to correct the wrong Japanses characters and output the corresponding correct Japanese sentence.\n","\"\"\""],"metadata":{"id":"WUpkuLay4f2X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Rinna"],"metadata":{"id":"WSGpmHPK-Fvz"}},{"cell_type":"markdown","source":["### Japanese Word Generation"],"metadata":{"id":"_cnSbmFW-Fv3"}},{"cell_type":"code","source":["f\"\"\"\n","以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。ローマ字の入力を、日本語の文字に正確に変換してください。\n","\n","### 指示:\n","ローマ字を日本語の文字に変換してください。可能な限り正確に翻訳してください。\n","\n","### 入力:\n","{input}\n","\n","### 応答:\n","\"\"\""],"metadata":{"id":"9Gxu_Mq9-Fv4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Japanese Sentence Generation"],"metadata":{"id":"BeaxOiFn-Fv4"}},{"cell_type":"code","source":["f\"\"\"\n","以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。ローマ字の入力を、日本語の文字に正確に変換してください。\n","\n","### 指示:\n","ユーザーからローマ字を与えられたら、対応する日本語を出力してみます。\n","\n","### 入力:\n","{input}\n","\n","### 応答:\n","\"\"\""],"metadata":{"id":"kp4p7wog-Fv4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Japanese Error Correction"],"metadata":{"id":"GohnR04k-Fv5"}},{"cell_type":"markdown","source":["Romaji Correction"],"metadata":{"id":"wF6N6VBuIMgd"}},{"cell_type":"code","source":["f\"\"\"\n","以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n","\n","### 指示:\n","ローマ字を修正して日本語訳を返してください。\n","\n","### 入力:\n","{romanji}\n","\n","### 応答:\n","\"\"\""],"metadata":{"id":"ZhnUnPhy-Fv6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Japanese Character Correction"],"metadata":{"id":"5M_gmrFhIKAb"}},{"cell_type":"code","source":["f\"\"\"\n","以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\n","\n","### 指示:\n","入力された文章を修正し、日本語の文章を返します\n","\n","### 入力:\n","{input}\n","\n","### 応答:\n","\"\"\""],"metadata":{"id":"me0NcHRZICD4"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1AZlda_kqNZ4H-zI0OlMGioQd4Ilw9-Co","timestamp":1742931514632},{"file_id":"1VmUcJPQI_bD2FQxUDjVv73pyhAFODj0R","timestamp":1724164245902},{"file_id":"1OtMKPZNXSfBdNwtkUKMdcYlMyox1O0d_","timestamp":1721796714388}],"collapsed_sections":["fY9UGuPIhOSS","5MK8O2rqClvo","niM3j0TIOSsl","M9WxgTlCK-MO","5E3Iz_islY7a"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}